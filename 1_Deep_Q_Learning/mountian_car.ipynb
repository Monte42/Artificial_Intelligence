{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q Mountain Car\n",
    "---\n",
    "In this game, the agent is an underpowered car.\\\n",
    "It can't generate enough torque to get moving, but not climb the hill.\\\n",
    "The object is for the agent to learn to use both hills and momentum to reach the goal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pip Requirements\n",
    "```\n",
    "pip install gymnasium torch numpy torchmetrics\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing like always is to install any packages we'll use, if not already installed.\\\n",
    "Two new ones I used here are matplotlib and torchmetrics.\\\n",
    "These were both used to help better visualize our agents results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random # Used to generate random float values, or make random choices from an array\n",
    "import numpy as np # Used for data conversion, extraction, and manipulation\n",
    "import gymnasium as gym # Provides us an environment and task for the agent\n",
    "import torch # Pytorch\n",
    "import torch.nn as nn # Neural Network, used to build the Network\n",
    "import torch.optim as optim # Provides optimizer function to maximize preformance of the model\n",
    "import torch.nn.functional as F # Gives us .mse_loss, calculate the loss ( diff between Pred and Trag ) and then rectifier function\n",
    "from torchmetrics.classification import MulticlassAccuracy # This compares the predicted probabilities to the target result \n",
    "import matplotlib.pyplot as plt # We use this to plot the loss and accurracy on a graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameters\n",
    "To Change the way the agent learns make changes in the cell below.\\\n",
    "This will affect the agent and evironment accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 50 # The number of time the agent will play the game\n",
    "\n",
    "capacity = 100000 # The total size of the agents memory 100,000\n",
    "sample_size = 50 # Number experiences used to train the agent per training iteration or EPOCH\n",
    "\n",
    "learning_rate = .000011 # Also known as Alpha, this is used for model optimization and to calculate Q-Values\n",
    "discount_factor = 0.98 # A.K.A. Gamma, when learning, this determins the weight of future Q-values when calculation current Q-value\n",
    "interpolation_parameter = 1e-3 # This determins the weights of both the local and target networks when updating the Target Network.\n",
    "\n",
    "epsilon_start = 1.0 # The probability the agent will experience a random event despite its outcome 1.0 is 100%\n",
    "epsilon_end = 0.1 # This is the final probability for random events\n",
    "epsilon_decay_rate = 1.2 / episodes # This is the amount removed from esilon decrease the random events and increasing the agents involvment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non Learning Related Variables\n",
    "If you would like to create a new model and not overwrite an existing one, change FILE variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = './models/DQN_mountain_car(x).pth' # The desired path for your saved model\n",
    "\n",
    "loss_hist = [] # Store agents loss history for plotting later\n",
    "acc_hist = [] # Store agents accuracy history for plotting later\n",
    "score_hist = [] # Store agents accuracy history for plotting later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MountainCar-v0\", render_mode=None)\n",
    "\n",
    "state_size = env.observation_space.shape[0] # We call shape on the first element in the observation space to get the number of input features\n",
    "action_size = env.action_space.n # Action space .n will give us the available number of actions, or outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artifical Neural Network\n",
    "Here we can add/remove layers and nerons to the network to alter the preformance of the agent.\\\n",
    "If we add/remove layers, make sure we add/remove them from the forward method also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module): # Our Network Module will inherit the torch.nn.Module / which gives use prebuilt training tools \n",
    "    def __init__(self, state_size, action_size, seed=42):\n",
    "        super(Network, self).__init__() # nn.Module has multiple parent classes, we pass Network as a param to ensure we inherit all methods correctly\n",
    "        self.seed = seed # Seed is like a set starting point for all the random adjustment the model will make during training (Doesn't have to be 42)\n",
    "        self.fc1 = nn.Linear(state_size, 640) # As we are building an ANN we will use the Linear layers\n",
    "        self.fc2 = nn.Linear(640,1228) # the first argument is the # of neurons in the first layer and the second is the following layers neurons\n",
    "        self.fc3 = nn.Linear(1228,1228) # Note that the first argument matches the second argument of the previous layer\n",
    "        self.fc4 = nn.Linear(1228,640) # This is becuase the are \"fully onnected\" layers\n",
    "        self.fc5 = nn.Linear(640, action_size) # Also see that the state_size and action_size are first and last as the are inputs and ouputs.\n",
    "\n",
    "    def forward(self, state): # This is forward propagation / where we will pass the observation through the model\n",
    "        x = F.relu(self.fc1(state)) # We will pass the observation through every layer\n",
    "        x = F.relu(self.fc2(x)) # Using the Rectifier Activation Fucntion, which basically turns neg outputs to 0\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        return self.fc5(x) # The raw output layer is returned so not to alter the models probablilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replay Memory\n",
    "In order for a neural network to learn, we will need large amounts of already existing data containing both input and output values.\\\n",
    "Since in this case the agent will learn from its own experiences, we will need to store each experience for later training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\") # Checks machine for GPU to storage, otherwise uses cpu\n",
    "        self.capacity = capacity # number of events to store\n",
    "        self.memory = [] # array to store each event\n",
    "\n",
    "    def push(self, event):\n",
    "        self.memory.append(event) # adds event to memory\n",
    "        if len(self.memory) > self.capacity:\n",
    "            del self.memory[0] # deletes oldest memory exceeds allocated size\n",
    "\n",
    "    def sample(self, sample_size):\n",
    "        experiences = random.sample(self.memory, sample_size) # random.sample(list, num_of_els) / grabs random elements from a list\n",
    "        # The next 5 lines puts each element into its own list and converts that list into a torch tensor\n",
    "        states = torch.from_numpy(np.vstack([e[0] for e in experiences if e is not None])).float().to(self.device) # .to(self.device) is\n",
    "        actions = torch.from_numpy(np.vstack([e[1] for e in experiences if e is not None])).long().to(self.device) # placing tensor in the \n",
    "        rewards = torch.from_numpy(np.vstack([e[2] for e in experiences if e is not None])).float().to(self.device) # location determined \n",
    "        next_states = torch.from_numpy(np.vstack([e[3] for e in experiences if e is not None])).float().to(self.device) # above\n",
    "        terminations = torch.from_numpy(np.vstack([e[4] for e in experiences if e is not None]).astype(np.uint8)).float().to(self.device)\n",
    "        # We then return each new tensor, NOTE the order they are returned.  We will unpack this later\n",
    "        return states, next_states, actions, rewards, terminations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available else \"cpu\") # set storage location\n",
    "        self.state_size = state_size \n",
    "        self.action_size = action_size\n",
    "        self.local_network = Network(state_size, action_size).to(self.device) # Next 2 lines will initiate the learing models\n",
    "        self.target_network = Network(state_size, action_size).to(self.device) # Local will make preds, target we'll apply Bellmans equations\n",
    "        self.optimizer = optim.Adam(self.local_network.parameters(), lr = learning_rate) # This use wieghts, biases, leanring rate to optimize the model\n",
    "        self.acc = accuracy = MulticlassAccuracy(num_classes=3).to(self.device) # Checks accuracy of local network vs. target network /w Bellmans   \n",
    "        self.memory = Memory(capacity)\n",
    "        self.t_step = 0 # \"Time Step\" counts every time agent commits to an action\n",
    "        self.l_step = 0\n",
    "\n",
    "    def step(self, state, action, reward, next_state, terminated):\n",
    "        self.memory.push((state,action,reward,next_state,terminated)) # Adds a tuple (event) to the agents memory using our Memory.push() method \n",
    "        self.t_step = (self.t_step + 1) % 1000 # Adds 1 to t_step, resets to 0 on every 4th iteration\n",
    "        if self.t_step == 0:\n",
    "            if len(self.memory.memory) > sample_size: # Checks agents memory for sufficent data, can be as small as sample_size\n",
    "                experiences = self.memory.sample(sample_size) # collects random experiences useing Memory.sample()\n",
    "                self.learn(experiences, discount_factor) # Calls the agents learn method, which we define shortly\n",
    "\n",
    "    def act(self, state, epsilon):\n",
    "        st = torch.from_numpy(state).float().unsqueeze(0).to(self.device) # converts state into tensor of float vals, and correct dimensions\n",
    "        self.local_network.eval() # method from nn.Module, applys current model params to the network\n",
    "        with torch.no_grad(): # We wont back propagate when acting, no need for gradient calculations, saves computer memory consumption\n",
    "            action = self.local_network(st) # Pass state through the local network to get the probabilites of the best action\n",
    "        self.local_network.train() # This informs the model that its training / some layers preform differently when training\n",
    "        if random.random() > epsilon: # Gens a random float, if float greater tha epsilon\n",
    "            return np.argmax(action.cpu().data.numpy()) #  return index of action with greatest probablility\n",
    "        else: # Other wise choose a weighted random action based on agents position / help encourage positive first events\n",
    "            if state[1] > 0:\n",
    "                action = random.choices(np.arange(self.action_size),weights=(20,20,60))\n",
    "            else:\n",
    "                action = random.choices(np.arange(self.action_size),weights=(60,20,20))\n",
    "            return action[0]\n",
    "\n",
    "    def learn(self, experiences, discount_factor):\n",
    "        states, next_states, actions, rewards, terminations = experiences # Unpack the experiences \n",
    "        states = self.local_network(states)\n",
    "        next_states = self.target_network(next_states)\n",
    "        next_states = rewards + discount_factor * next_states * (1 - terminations)\n",
    "        next_q_targets = next_states.detach().max(1)[0].unsqueeze(1) # get best action of all next states / TARGET\n",
    "        # q_targets = rewards + discount_factor * next_q_targets * (1 - terminations) # Apply a variation of the Bellmans equation\n",
    "        q_expected = states.gather(1, actions) # get best action of all current states / PREDICTED\n",
    "        loss = F.mse_loss(q_expected, next_q_targets) # mse_loss returns the mean squared error of differences between models\n",
    "        loss.backward() # Uses the loss the update the weights and biases in the network at the end of gradient computations\n",
    "        self.optimizer.step() # Uses the learning rate to update the weights and biases in the network at the end of every step\n",
    "        self.soft_update(self.local_network, self.target_network, interpolation_parameter) # Brings the 2 networks closer together in results\n",
    "        self.l_step = (self.l_step + 1) % 4 # Adds 1 to t_step, resets to 0 on every 4th iteration\n",
    "        if self.l_step == 0:\n",
    "            self.accuracy(loss, states, next_states)\n",
    "\n",
    "    def soft_update(self, local_model, target_model, interpolation_parameter):\n",
    "        # combines the array params of both networks, then iterates over the \"new\" list, and unpacks the values of each \"new\" nested array\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            # In the target network we update the params to be equalt to: a small & of the local params PLUS a large % of the target params\n",
    "            target_param.data.copy_(interpolation_parameter * local_param.data + (1.0 - interpolation_parameter) * target_param.data)\n",
    "\n",
    "    def accuracy(self, loss, states, next_states):\n",
    "        accuracy = self.acc(states, torch.max(next_states, dim=1)[1])\n",
    "        loss_hist.append(float(loss))\n",
    "        acc_hist.append(float(accuracy))\n",
    "        print(f'Loss:{loss}\\tAccuracy: {round(float(accuracy)*100)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate Agent\n",
    "Get its own cell to avoid re-initializing agent and dumping its memory.\\\n",
    "Of course if the Agents learning model exceeds the recent best the agents memory will be irrelevant,\\\n",
    "as we will have the parameters on file that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size,action_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training The Agent\n",
    "To see the un-trained agent, play the next cell first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.09329874068498611\tAccuracy: 6%\n",
      "Loss:0.16813109815120697\tAccuracy: 0%\n",
      "Loss:0.09298310428857803\tAccuracy: 0%\n",
      "Loss:0.16219289600849152\tAccuracy: 0%\n",
      "Loss:0.1234714686870575\tAccuracy: 4%\n",
      "Best set // 0.0\n",
      "Loss:0.03756150230765343\tAccuracy: 22%\n",
      "Best set // 0.0\n",
      "Best set // 38.0\n",
      "Best set // 202.0\n",
      "Loss:0.07163595408201218\tAccuracy: 31%\n",
      "Loss:0.08679284155368805\tAccuracy: 33%\n",
      "Loss:0.08596298098564148\tAccuracy: 37%\n",
      "Loss:0.06934117525815964\tAccuracy: 42%\n"
     ]
    }
   ],
   "source": [
    "epsilon = epsilon_start # resent the epsilion the difined value above\n",
    "\n",
    "try: # Checks to see if the above file exists\n",
    "    best_model = torch.load(FILE) # creates a new dict for store the best saved models information / Dose not set current model\n",
    "except: # If file does not exist\n",
    "    best_model = {'best': 0} # Create dict with one key with a value 0\n",
    "\n",
    "for e in range(1, episodes+1): # we do range(1, end+1) for logging reasons\n",
    "    terminated = False # When the game is over the env will return terminated as True\n",
    "    state,_ = env.reset() # .reset will reset the game, return an array with two values, unpack and take 1st val\n",
    "    score = 1000\n",
    "\n",
    "    while(not terminated and score > 0):\n",
    "        action = agent.act(state, epsilon) # As defned returns an int within the action space\n",
    "        next_state, reward, terminated,truncated,_ = env.step(action) # applies action to env, unpacts results\n",
    "        score += reward\n",
    "        if terminated: # While training, we didn't set a set limit, so the game only ends when the agents hits the goal\n",
    "            reward = 10 # give a reward of 10\n",
    "        # NOTE when the agents steps the game issues a reward of -1. This wont help the agent know its pos/vel in relation to the goal\n",
    "        elif next_state[1] > 0: # If agents velocity is a neg val (moving away from goal)\n",
    "            if next_state[0] < 0: # If agents position is less than 50% away from the goal\n",
    "                reward = (next_state[0]*-1)*next_state[1] # Small positive reward\n",
    "        elif next_state[1] < 0 and next_state[0] < 0: # If agent more than 50% away with neg velocity\n",
    "                reward = (next_state[0]*next_state[1])*0.1 # Very small positive reward\n",
    "        else: \n",
    "            reward = reward - next_state[0]*next_state[1] # Negative reward based on position and velocity\n",
    "        agent.step(state, action, reward, next_state, terminated) # push event to memory, learn on every 4th step\n",
    "        state = next_state # set state to the new state for the next iteration\n",
    "    epsilon = max(0.05, epsilon - epsilon_decay_rate) # Adjusts epsilon to decrease random events\n",
    "    # Checks random events are < 10%, accuarcy is > 0 (can't divid by 0), and accuracy is < 1 (100% will affect the effectiveness of the best_model)\n",
    "    if epsilon <= 0.3 and acc_hist[-1] > 0.0 and acc_hist[-1] < 1.0:\n",
    "        loss_acc = (acc_hist[-1]) / loss_hist[-1] # Return lager value when accuracy is high and loss is low\n",
    "        if loss_acc + score > best_model['best']: # Compares this value to our best_model\n",
    "            best_model = {  # Updates best_model dict\n",
    "                'best': loss_acc + score,\n",
    "                'local_network': agent.local_network.state_dict(),\n",
    "                'target_network': agent.target_network.state_dict()\n",
    "            }\n",
    "            torch.save(best_model, FILE) # Saves dict containing model score and params\n",
    "            print(f'Best set // {score}')\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the results\n",
    "This is really outside the scope of machine learning,\\\n",
    "but it helps to visulaize at which part in the training did the model preform the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c10d4a05b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x270 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 2.7), layout='constrained')\n",
    "plt.plot(loss_hist, label='loss')\n",
    "plt.plot(acc_hist, label='acc')\n",
    "plt.plot(score_hist, label='score')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('...')\n",
    "plt.title(\"Training Results\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a saved model\n",
    "This section is will set the params of our agent to match out best_model.\\\n",
    "If we intend to run and save a new model, we should update the FILE var above as not to overwrite an existing model.\\\n",
    "There are 4 models on file:\n",
    " - **'./models/DQN_mountain_car.pth'** - *Scores(500-650)*\n",
    " - **'./models/DQN_mountain_car(2).pth'** - *Scores(May not even complete)*\n",
    " - **'./models/DQN_mountain_car(3).pth'** - *Scores(650-800)*\n",
    " - **'./models/DQN_mountain_car(x).pth'** - *The Working File*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=2, out_features=640, bias=True)\n",
       "  (fc2): Linear(in_features=640, out_features=1228, bias=True)\n",
       "  (fc3): Linear(in_features=1228, out_features=1228, bias=True)\n",
       "  (fc4): Linear(in_features=1228, out_features=640, bias=True)\n",
       "  (fc5): Linear(in_features=640, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.local_network.load_state_dict(torch.load(FILE)['local_network'])\n",
    "agent.local_network.eval()\n",
    "agent.target_network.load_state_dict(torch.load(FILE)['target_network'])\n",
    "agent.target_network.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Agent And Visualize Results\n",
    "In this section there really isn't much to cover.\n",
    "Just know that all training and learning methods have been removed.\\\n",
    "Only a 10% of a weighted random event remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1\tScore: 723.0\n",
      "Episode:2\tScore: 709.0\n",
      "Episode:3\tScore: 702.0\n",
      "Episode:4\tScore: 789.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"MountainCar-v0\", render_mode='human') # render_mode='human' will display the environment so we can watch\n",
    "\n",
    "for i in range(1,5):\n",
    "    terminated = False\n",
    "    state,_ = env.reset()\n",
    "    score = 1000\n",
    "\n",
    "    while(not terminated and score > 0):\n",
    "        action = agent.act(state, .01)\n",
    "        next_state, reward, terminated,_,_ = env.step(action)\n",
    "\n",
    "        state = next_state\n",
    "        score += reward\n",
    "    print(f'Episode:{i}\\tScore: {score}')\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
