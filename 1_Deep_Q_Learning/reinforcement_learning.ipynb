{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinenforcement Learning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In reinenforcement learning, you essentially have and environment and a goal or task.\\\n",
    "Then you will have an agent, or the A.I.\\\n",
    "The Agent will preform an action to the environment, and in return the agent will be given a reward and a new state.\\\n",
    "A state can be something like its position in the environment or anything that can be described by a set of parameters.\\\n",
    "\\\n",
    "Not every action changes the state, and not every action returns a reward.\\\n",
    "None the less, the agent will continue this cycle exploring its environment, looking for better states and better rewards.\\\n",
    "\\\n",
    "Rewards are normally values of +1/-1 or 1/0.\\\n",
    "The agent could get the reward after completing the goal, or it can receive rewards through its process.\\\n",
    "So the plan is, when the agent does something good, it will get a +1.\\\n",
    "If the agent does something wrong it will recive nothing or a -1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bellman Equation\n",
    "---\n",
    "This well be just an introduction to the Bellman equation.\\\n",
    "As the course goes on we'll add more to this equation.\\\n",
    "\\\n",
    "Concepts:\n",
    "- s - State, the state the agent is in, or any state the agent can be in\n",
    "- a - Action, any actions the agent can take\n",
    "- R - Reward, thats the reward the agent will get for entering a certain state\n",
    "- $\\gamma$ - Discount, See below for more on the Discount\n",
    "> ### $$V(s)=\\max_{a}(R(s,a)+\\gamma V(s'))$$\n",
    "What we a looking for is the value of a certain state. $V(s)$\\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
